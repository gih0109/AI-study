{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 역전파\n",
    "# 모델 파라미터의 최적화 -> 역전파 ; 미분의 성질과 연쇄법칙 기반\n",
    "# 파이토치에서 다양한 최적화 방법 제공 \n",
    "\n",
    "# 그래디언트 텐서\n",
    "# 신경망의 최적화 -> 손실함수가 최소값이 나오게 하는것 ; 미분 필수\n",
    "# 파이토치는 자동 미분 계산 함수 제공\n",
    "# 그래디언트 : 미분값의 모임(배열) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:  tensor(8., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(2, 2, requires_grad=True) # x 에 대한 연쇄 법칙을 이용한 미분 가능 z -> y -> x\n",
    "# requires_grad=True : 해당 텐서를 기준으로 모든 연산 추적 -> 그래디언트 계산 가능\n",
    "\n",
    "y = x + 1 # y 는 x 에 대한 함수\n",
    "z = 2 * y ** 2 # z 는 y 에 대한 함수\n",
    "r = z.mean() # r 은 z 에 대한 식, mean : 텐서에 있는 모든 요소의 평균값 반환\n",
    "print(\"Result: \", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# backward : r 기준 역전파 진행 ; dr/dx 계산한다\n",
    "r.backward() \n",
    "print(x.grad) # grad : 그래디언트 계산"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48bde174e9cd0039e04545d8ab8de3430bce749efc257b14db65b6584328569a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
