{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "# 데이터를 배치 형태로 만드는 법과 데이터를 전처리하는 방법에 대해 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision # 이미지와 관련된 파이토치 라이브러리\n",
    "import torchvision.transforms as tr # 이미지 전처리 기능을 제공하는 라이브러리\n",
    "from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# tr.Compose 내에 원하는 전처리를 차례대로 넣어주면 된다.\n",
    "transf = tr.Compose([tr.Resize(16), tr.ToTensor()]) # 예시 : 16x16 으로 이미지 크기 변환 후 텐서 타입으로 변환\n",
    "# 원본 이미지의 너비, 높이가 다를 경우 각각 지정해줘야함 ; tr.Resize((16, 16))\n",
    "\n",
    "# torchvision.datasets 에서 제공하는 CIFAR10 데이터를 불러오기 \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transf)\n",
    "# root : 다운로드 받을 경로\n",
    "# train = True : 학습 데이터 불러오기, False : 테스트 데이터 불러오기\n",
    "# transform = transf : 미리 선언한 전처리 사용하기 \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 크기\n",
    "print(trainset[0][0].size())\n",
    "\n",
    "# 데이터셋 = 이미지와 라벨이 동시에 들어있는 튜플 형태\n",
    "# trainset[0] : 학습 데이터의 첫 번째 데이터 ; 이미지 한 장과 라벨 숫자 하나가 저장되어 있음\n",
    "# trainset[0][0] : 이미지 , trainset[0][1] : 라벨\n",
    "# 이미지 사이즈 3 x 16 x 16 ; 3 : 채널수, 16x16 : 이미지의 너비와 높이 의미\n",
    "# 컬러 사진은 RGB 이미지이므로 채널이 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader : 데이터를 미니 배치 형태로 만들어준다. 배치 데이터에 관한 배치 사이즈 및 셔플 여부 선택 가능\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True) \n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=False)\n",
    "# batch_size=50, shuffle=True : 무작위로 데이터를 섞어 한 번에 50개의 이미지를 묶은 배치로 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)\n",
    "# CIFAR10 의 학습 이미지는 50000 장이고 배치 사이즈가 50장 -> 배치의 개수 : 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# 배치 이미지 확인\n",
    "images, labels = iter(trainloader).next() # iter, next 함수 이용해 trainloader 첫 번째 배치 불러오기\n",
    "print(images.size()) # 배치 사이즈 ; (배치 크기) x (채널 수) x (너비) x (높이) 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "oneshot = images[1].permute(1, 2, 0).numpy()\n",
    "# image[1] 크기 : (3, 16, 16)\n",
    "# 그림을 그려주기 위해서는 채널 수가 가장 뒤로 가는 형태 (16, 16, 3) 으로 변형해야함 -> permute(1, 2, 0)\n",
    "# permute(1, 2, 0) 은 기존 차원의 위치인 (0, 1, 2) 를 (1, 2, 0) 으로 바꾸는 함수\n",
    "# 마지막으로 numpy() 로 넘파이 배열로 변환\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(oneshot)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 클래스 별로 폴더를 정리한 경우\n",
    "\n",
    "# 데이터가 같은 클래스 별로 미리 폴더를 정리한 경우, ImageFolder 하나로 개인 데이터 사용 가능\n",
    "# 폴더 별로 자동 라벨링 -> 별도로 라벨링 할 필요 없음\n",
    "# 마지막으로 ImageFolder 에 상위 폴더 ./class 를 입력하면 이미지와 라벨이 정리되어 데이터를 불러온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf = tr.Compose([tr.Resize(128), tr.ToTensor()])\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n",
    "trainloader = DataLoader(trainset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정리되지 않은 커스텀 데이터 불러오기\n",
    "\n",
    "# ImageFolder 를 이용하면 매우 간단하게 이미지 데이터를 사용할 수 있지만 여러 가지 이유로 사용 불가능한 경우\n",
    "# 1. 라벨 별로 폴더 정리가 되어 있으면 매우 좋겠지만 그렇지 않은 경우가 많다\n",
    "# 2. 정리를 하고 싶지만 다른 작업들과 공유된 데이터인 경우 폴더를 함부로 정리할 수 없다\n",
    "# 3. 이미지 데이터라도 이미지가 아닌 텍스트, 리스트, 배열 등의 다른 형대로 저장되어 있는 경우도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터 불러오기 기본 형태\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class classname(Dataset): # Dataset 을 상속받아 DataLoader 에서 배치 단위로 불러올 수 있게 해준다\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __getitem__(self, index): # DaataLoader 를 통해 샘플이 요챙되면 __getitem__ 은 인덱스에 해당하는 샘플을 찾아서 준다\n",
    "        pass\n",
    "    def __len__(self): # __len__ 은 크기를 반환한다\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 데이터 세트 예시\n",
    "# 32x32 크기인 RGB 컬러 이미지 100장과 그에 대한 라벨이 되어있고 넘파이 배열로 정리가 되어 있다고 가정\n",
    "\n",
    "train_images = np.random.randint(256, size=(100, 32, 32, 3))/255\n",
    "train_labels = np.random.randint(2, size=(100, 1))\n",
    "\n",
    "class TensorData(Dataset):\n",
    "\n",
    "    def __init__(self, x_data, y_data):\n",
    "        self.x_data = torch.FloatTensor(x_data) # 데이터를 텐서로 변환\n",
    "        self.x_data = self.x_data.permute(0, 3, 1, 2) # 이미지 크기 (100, 32, 32, 3) -> (100, 3, 32, 32) 로 변환\n",
    "        self.y_data = torch.LongTensor(y_data) # 데이터를 텐서로 변환\n",
    "        self.len = self.y_data.shape[0] # 입력 데이터의 개수에 대한 변수 self.len 생성\n",
    "    \n",
    "    def __getitem__(self, index): # 뽑아낼 데이터에 대해 인덱스 처리\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self): # 미리 선언한 self.len 반환\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorData 클래스를 train_data 로 정의하여 DataLoader 에 넣어 배치 데이터 형태로 사용 가능\n",
    "train_data = TensorData(train_images, train_labels)\n",
    "train_loder = DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48bde174e9cd0039e04545d8ab8de3430bce749efc257b14db65b6584328569a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
