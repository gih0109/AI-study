{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스로 로지스틱 회귀 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 구현한 로지스틱 회귀\n",
    "model = nn.Sequetial(\n",
    "    nn.Linear(),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스로 구현\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear()\n",
    "        self.sigmoid = nn.sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))\n",
    "\n",
    "# 대부분 파이토치 구현체에서 사용하고 있는 방식으로 반드시 숙지 필요\n",
    "# class 형태의 모델은 nn.Module 을 상속\n",
    "# __init__() 에서 모델의 구조와 동작을 정의하는 생성자를 정의\n",
    "# super() 함수를 부르면 여기서 만든 클래스는 nn.Module 클래스의 속성을 가지고 초기화\n",
    "# forword() 함수는 model 객체를 데이터와 함께 호출하면 자동으로 실행이 된다.\n",
    "\n",
    "# H(x) 식에 입력 x 로부터 예측된 y 를 얻는 것을 forwward 연산이라고 한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25f065ec290>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회귀 클래스로 구현\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 선언\n",
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 0.539713 Accuracy 83.33%\n",
      "Epoch   10/1000 Cost: 0.614851 Accuracy 66.67%\n",
      "Epoch   20/1000 Cost: 0.441875 Accuracy 66.67%\n",
      "Epoch   30/1000 Cost: 0.373145 Accuracy 83.33%\n",
      "Epoch   40/1000 Cost: 0.316358 Accuracy 83.33%\n",
      "Epoch   50/1000 Cost: 0.266094 Accuracy 83.33%\n",
      "Epoch   60/1000 Cost: 0.220498 Accuracy 100.00%\n",
      "Epoch   70/1000 Cost: 0.182095 Accuracy 100.00%\n",
      "Epoch   80/1000 Cost: 0.157299 Accuracy 100.00%\n",
      "Epoch   90/1000 Cost: 0.144091 Accuracy 100.00%\n",
      "Epoch  100/1000 Cost: 0.134272 Accuracy 100.00%\n",
      "Epoch  110/1000 Cost: 0.125769 Accuracy 100.00%\n",
      "Epoch  120/1000 Cost: 0.118297 Accuracy 100.00%\n",
      "Epoch  130/1000 Cost: 0.111680 Accuracy 100.00%\n",
      "Epoch  140/1000 Cost: 0.105779 Accuracy 100.00%\n",
      "Epoch  150/1000 Cost: 0.100483 Accuracy 100.00%\n",
      "Epoch  160/1000 Cost: 0.095704 Accuracy 100.00%\n",
      "Epoch  170/1000 Cost: 0.091369 Accuracy 100.00%\n",
      "Epoch  180/1000 Cost: 0.087420 Accuracy 100.00%\n",
      "Epoch  190/1000 Cost: 0.083806 Accuracy 100.00%\n",
      "Epoch  200/1000 Cost: 0.080486 Accuracy 100.00%\n",
      "Epoch  210/1000 Cost: 0.077425 Accuracy 100.00%\n",
      "Epoch  220/1000 Cost: 0.074595 Accuracy 100.00%\n",
      "Epoch  230/1000 Cost: 0.071969 Accuracy 100.00%\n",
      "Epoch  240/1000 Cost: 0.069526 Accuracy 100.00%\n",
      "Epoch  250/1000 Cost: 0.067248 Accuracy 100.00%\n",
      "Epoch  260/1000 Cost: 0.065118 Accuracy 100.00%\n",
      "Epoch  270/1000 Cost: 0.063122 Accuracy 100.00%\n",
      "Epoch  280/1000 Cost: 0.061247 Accuracy 100.00%\n",
      "Epoch  290/1000 Cost: 0.059483 Accuracy 100.00%\n",
      "Epoch  300/1000 Cost: 0.057820 Accuracy 100.00%\n",
      "Epoch  310/1000 Cost: 0.056250 Accuracy 100.00%\n",
      "Epoch  320/1000 Cost: 0.054764 Accuracy 100.00%\n",
      "Epoch  330/1000 Cost: 0.053357 Accuracy 100.00%\n",
      "Epoch  340/1000 Cost: 0.052022 Accuracy 100.00%\n",
      "Epoch  350/1000 Cost: 0.050753 Accuracy 100.00%\n",
      "Epoch  360/1000 Cost: 0.049546 Accuracy 100.00%\n",
      "Epoch  370/1000 Cost: 0.048396 Accuracy 100.00%\n",
      "Epoch  380/1000 Cost: 0.047299 Accuracy 100.00%\n",
      "Epoch  390/1000 Cost: 0.046252 Accuracy 100.00%\n",
      "Epoch  400/1000 Cost: 0.045251 Accuracy 100.00%\n",
      "Epoch  410/1000 Cost: 0.044294 Accuracy 100.00%\n",
      "Epoch  420/1000 Cost: 0.043376 Accuracy 100.00%\n",
      "Epoch  430/1000 Cost: 0.042497 Accuracy 100.00%\n",
      "Epoch  440/1000 Cost: 0.041653 Accuracy 100.00%\n",
      "Epoch  450/1000 Cost: 0.040843 Accuracy 100.00%\n",
      "Epoch  460/1000 Cost: 0.040064 Accuracy 100.00%\n",
      "Epoch  470/1000 Cost: 0.039315 Accuracy 100.00%\n",
      "Epoch  480/1000 Cost: 0.038593 Accuracy 100.00%\n",
      "Epoch  490/1000 Cost: 0.037898 Accuracy 100.00%\n",
      "Epoch  500/1000 Cost: 0.037228 Accuracy 100.00%\n",
      "Epoch  510/1000 Cost: 0.036582 Accuracy 100.00%\n",
      "Epoch  520/1000 Cost: 0.035958 Accuracy 100.00%\n",
      "Epoch  530/1000 Cost: 0.035356 Accuracy 100.00%\n",
      "Epoch  540/1000 Cost: 0.034773 Accuracy 100.00%\n",
      "Epoch  550/1000 Cost: 0.034210 Accuracy 100.00%\n",
      "Epoch  560/1000 Cost: 0.033664 Accuracy 100.00%\n",
      "Epoch  570/1000 Cost: 0.033137 Accuracy 100.00%\n",
      "Epoch  580/1000 Cost: 0.032625 Accuracy 100.00%\n",
      "Epoch  590/1000 Cost: 0.032130 Accuracy 100.00%\n",
      "Epoch  600/1000 Cost: 0.031649 Accuracy 100.00%\n",
      "Epoch  610/1000 Cost: 0.031183 Accuracy 100.00%\n",
      "Epoch  620/1000 Cost: 0.030730 Accuracy 100.00%\n",
      "Epoch  630/1000 Cost: 0.030291 Accuracy 100.00%\n",
      "Epoch  640/1000 Cost: 0.029864 Accuracy 100.00%\n",
      "Epoch  650/1000 Cost: 0.029449 Accuracy 100.00%\n",
      "Epoch  660/1000 Cost: 0.029046 Accuracy 100.00%\n",
      "Epoch  670/1000 Cost: 0.028654 Accuracy 100.00%\n",
      "Epoch  680/1000 Cost: 0.028272 Accuracy 100.00%\n",
      "Epoch  690/1000 Cost: 0.027900 Accuracy 100.00%\n",
      "Epoch  700/1000 Cost: 0.027538 Accuracy 100.00%\n",
      "Epoch  710/1000 Cost: 0.027186 Accuracy 100.00%\n",
      "Epoch  720/1000 Cost: 0.026842 Accuracy 100.00%\n",
      "Epoch  730/1000 Cost: 0.026507 Accuracy 100.00%\n",
      "Epoch  740/1000 Cost: 0.026181 Accuracy 100.00%\n",
      "Epoch  750/1000 Cost: 0.025862 Accuracy 100.00%\n",
      "Epoch  760/1000 Cost: 0.025552 Accuracy 100.00%\n",
      "Epoch  770/1000 Cost: 0.025248 Accuracy 100.00%\n",
      "Epoch  780/1000 Cost: 0.024952 Accuracy 100.00%\n",
      "Epoch  790/1000 Cost: 0.024663 Accuracy 100.00%\n",
      "Epoch  800/1000 Cost: 0.024381 Accuracy 100.00%\n",
      "Epoch  810/1000 Cost: 0.024104 Accuracy 100.00%\n",
      "Epoch  820/1000 Cost: 0.023835 Accuracy 100.00%\n",
      "Epoch  830/1000 Cost: 0.023571 Accuracy 100.00%\n",
      "Epoch  840/1000 Cost: 0.023313 Accuracy 100.00%\n",
      "Epoch  850/1000 Cost: 0.023061 Accuracy 100.00%\n",
      "Epoch  860/1000 Cost: 0.022814 Accuracy 100.00%\n",
      "Epoch  870/1000 Cost: 0.022572 Accuracy 100.00%\n",
      "Epoch  880/1000 Cost: 0.022336 Accuracy 100.00%\n",
      "Epoch  890/1000 Cost: 0.022104 Accuracy 100.00%\n",
      "Epoch  900/1000 Cost: 0.021877 Accuracy 100.00%\n",
      "Epoch  910/1000 Cost: 0.021655 Accuracy 100.00%\n",
      "Epoch  920/1000 Cost: 0.021437 Accuracy 100.00%\n",
      "Epoch  930/1000 Cost: 0.021224 Accuracy 100.00%\n",
      "Epoch  940/1000 Cost: 0.021015 Accuracy 100.00%\n",
      "Epoch  950/1000 Cost: 0.020810 Accuracy 100.00%\n",
      "Epoch  960/1000 Cost: 0.020609 Accuracy 100.00%\n",
      "Epoch  970/1000 Cost: 0.020412 Accuracy 100.00%\n",
      "Epoch  980/1000 Cost: 0.020219 Accuracy 100.00%\n",
      "Epoch  990/1000 Cost: 0.020029 Accuracy 100.00%\n",
      "Epoch 1000/1000 Cost: 0.019843 Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 게산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.binary_cross_entropy(hypothesis, y_train)\n",
    "\n",
    "    # cost 로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 10 == 0:\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5]) # 예측값이 0.5를 넘으면 True 로 간주\n",
    "        correct_prediction = prediction.float() == y_train # 실제값과 일치하는 경우만 True로 간주\n",
    "        accuracy = correct_prediction.sum().item() / len(correct_prediction) # 정확도를 계산\n",
    "\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(epoch, nb_epochs, cost.item(), accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48bde174e9cd0039e04545d8ab8de3430bce749efc257b14db65b6584328569a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
